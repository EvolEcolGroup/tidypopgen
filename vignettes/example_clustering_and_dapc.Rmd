---
title: "example workflow with tidypopgen"
output: rmarkdown::html_vignette
        #pdf_document
vignette: >
  %\VignetteIndexEntry{example_workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## An example workflow with real data
We will explore the genetic structure of *Anolis punctatus* in South America,
using data from Prates et al 2018. We downloaded the vcf file of the genotypes
from "https://github.com/ivanprates/2018_Anolis_EcolEvol/blob/master/data/VCFtools_SNMF_punctatus_t70_s10_n46/punctatus_t70_s10_n46_filtered.recode.vcf?raw=true" and compressed it to a vcf.gz file.

We read in the data from the compressed vcf with:
```{r}
library(tidypopgen)
vcf_path <- system.file("/extdata/anolis/punctatus_t70_s10_n46_filtered.recode.vcf.gz",
                          package = "tidypopgen")
bed_path <- gt_vcf_to_bed(vcf_path, bed_path = tempfile("anolis_"))
anole_gt <- gen_tibble(bed_path)
```
Note that the `gt_vcf_to_bed` function reads the whole vcf in memory before writing
the bed, so it is only suitable for smallish datasets.

Now let's inspect our `gen_tibble`:
```{r}
anole_gt
```

We can see that we have 46 individuals, from 3249 loci. Note that we don't have any
information on population from the vcf. That information can be found
from another file on the github repository ("https://github.com/ivanprates/2018_Anolis_EcolEvol/raw/master/data/plot_order_punctatus_n46.csv).
We will have add the population information manually. Let's start by reading the
file:
```{r}
pops_path <- system.file("/extdata/anolis/plot_order_punctatus_n46.csv",
                        package = "tidypopgen")
pops <- readr::read_csv(pops_path)
pops
```

The ids from the VCF are in a different format than the ones we just got from
the pop csv. We need a bit of string wrangling, but it looks easy, we just need
to remove "punc_":

Let us simplify the ids, which wll have a "punc_" prefix
```{r}
anole_gt <- anole_gt %>% mutate(id = gsub('punc_',"",.data$id,))
anole_gt
```

Now we can bring in the pop information:
```{r}
anole_gt <- anole_gt %>% mutate(population = pops$pop[match(pops$ID,.data$id)])
anole_gt
```

That was easy. The loci had already been filtered and cleaned, so we don't need 
to do any QC. Let us jump straight into analysis and run a PCA:
```{r, error=TRUE}
anole_pca <- anole_gt %>% gt_pca_partialSVD(k=30)
```
Ok, we jumped too quickly. There are missing data, and we need first 
to impute them:

```{r}
anole_gt <- gt_impute_simple(anole_gt)
```

And now:
```{r}
anole_pca <- anole_gt %>% gt_pca_partialSVD(k=30)
```

Let us look at the object:
```{r}
anole_pca
```

The `print` function (implicitly called when we type the name of the object)
gives us information about the most important elements in the object (and the names
of the elements in which they are stored).

We can extract those elements with the `tidy` function, which returns a tibble
that can be easily used for further analysis, e.g.:
```{r}
tidy(anole_pca, matrix="eigenvalues")

```
We can return information on the *eigenvalues*, *scores* and *loadings* of the pca.
There is also an `autoplot` method that allows to visualise those elements (type *screeplot* for
*eigenvalues*, type *scores* for *scores*, and *loadings* for *loadings*:
```{r}
autoplot(anole_pca, type="screeplot")
```

To plot the sample in principal coordinates space, we can simply use:
```{r}
autoplot(anole_pca, type ="scores")
```

`autoplots` are deliberately kept simple: they are just a way to quickly inspect the results.
They are `ggplot2` objects, and so they can be further embellished with the usual
`ggplot2` grammar:
```{r}
library(ggplot2)
autoplot(anole_pca, type = "scores") +
  aes(color = anole_gt$population) +
  labs(color = "population")

```
For more complex/publication ready plots, we will want to add the PC scores
to the tibble, so that we can create a custom plot with `ggplot2`. We can easily
add the data with the `augment` method:
```{r}
anole_gt <- augment(anole_pca , data = anole_gt)
```

And now we can use `ggplot2` directly to generate our plot:
```{r}
anole_gt %>% ggplot(aes(.fittedPC1, .fittedPC2, color = population)) + 
  geom_point()
```
We can see that the three population do separate nicely on the PCA, with just one individual
from Wam sitting inbetween the other Wam individuals and those from Eam.

# Explore population structure with DAPC

DAPC is a powerful tool to investigate population structure. It has the advantage of
scaling well to very large datasets. It does not have the assumptions of STRUCTURE or
ADMIXTURE (which also limits its power).

The first step is to determine the number of genetic clusters in the dataset. We could
test any a-priori grouping hypothesies, or we can use the data to suggest clusters. In this
case, we did not have any strong expectations of structure in our study system, so we will
go for the latter option in this case. We will use
a k-clustering algorithm applied to the principal components (allowing us to reduce
the dimensions from the thousands of loci to just a few tens of components). We need to decide how 
many components to use; this decision is often made based on a plot of the cumulative
explained variance of the components.
Using `tidy` on the `gt_pca` object allows us easily obtain those quantities, and it is then
trivial to plot them:
```{r}
library(ggplot2)
tidy(anole_pca,matrix="eigenvalues") %>%
  ggplot(mapping =aes(x=PC, y=cumulative)) +
  geom_point()

```

Note that, as we were working with a truncated SVD algorithm for our PCA, we can not easily
phrase the eigenvalues in terms of proportion of total variance, so the cumulative y axis simply
shows the cumulative sum of the eigen values. Ideally, we are looking for the point where 
the curve starts flattening. In this case, we can
not see a very clear flattening, but by PC 10 the increase in explained variance has markedly
decelerated. We can now find clusters based on those 10 PCs:

```{r}
anole_clusters <- gt_pca_find_clusters(anole_pca, n_pca = 10)
```

This object retains information about a large number of possible *k* (by default,
1 to 5, use the paramter `k` to change the range. To choose an appropriate
*k*, we plot the number of clusters against a measure of fit. BIC has been shown
to be a very good metric under many scenarios:
```{r}
autoplot(anole_clusters)
```

We are looking for the minimum value of BIC. There is no clear elbow (a minimum after which BIC increases
with increasing k). However, we notice that there is a quick levelling
off in the decrease in BIC at
3 clusters. Arguably, these are sufficient to capture the main structure (and that makes
sense given what we saw in the PCA). We can also use a number of algorithmic approaches (based on the original `find.clusters()` function in `adegenet`) to choose the best *k* value
from this plot through `gt_pca_clust_best_k()`. We will use the defaults (BIC with "diffNgroup",
see the help page for `gt_pca_clust_best_k()` for a description of the various options):
```{r}
anole_clusters <- gt_pca_clust_best_k(anole_clusters)
```
The algorithm confirms our choice. Note that this function simply adds an element
`$best_k` to the `gt_pca_clust` object:
```{r}
anole_clusters$best_k
```
If we decided that we wanted to explore a different value, we could simply overwrite
that number with `anole_clusters$best_k<-5`

In this case, we are happy with the option of 3 clusters, and we can run a DAPC:
```{r}
anole_dapc <- gt_dapc(anole_clusters)
```

Note that `gt_dapc()` takes automatically the number of clusters form the `anole_clusters` object,
but can change that behaviour by setting some of its parameters (see the help
page for `gt_dapc()`). When we print the object, we are given information about
the most important elements of the object and where to find them (as we saw for `gt_pca`):

```{r}
anole_dapc
```

Again, these elements can be obtained with tidiers (with `matrix` equal to `eigenvalues`,
`scores`,`ld_loadings` and `loci_loadings`):
```{r}
tidy(anole_dapc, matrix="eigenvalues")
```

And they can be visualised with `autoplot`:
```{r}
autoplot(anole_dapc, type="screeplot")
```

We can plot the scores with:
```{r}
autoplot(anole_dapc, type="scores")
```



`anole_dapc` is of class `gt_dapc`, which is a subclass of `dapc` from `adegenet`. `gt_dapc` has its
own tidiers and autoplot function, but it is possible to use a number of functions from `adegenet` if
the functionality is not yet available in `tidypopgen` (the only exception is `adegenet::predict.dapc`, 
which does not work because the underlying pca object is different).

`anole_dapc` is of class `dapc`, so we can use the standard `adegenet` functions:
```{r}
library(adegenet)
scatter(anole_dapc, posi.da="bottomright")
```

We can inspect the assignment by DAPC with `assignplot`, ordering the samples
by the original population label:
```{r}
assignplot(anole_dapc,subset=order(anole_gt$population))
```
We can see that all individuals but one assign back to their original population.

Or we can make a more conventional assignment plot:

```{r}
compoplot(anole_dapc, subset=order(anole_gt$population), posi="bottomright",
txt.leg=paste("Cluster", 1:3), lab="",
ncol=2, xlab="individuals", col=funky(3))
```
Note that, given the very clear separation we observed when plotting the LD scores,
no individual is modelled as a mixture, all assignments are with 100% probability 
to a single cluster.


# Clustering with sNMF

sNMF is a fast clustering algorithm which provides results similar to STRUCTURE and ADMIXTURE. We can run it directly form R. We have first to generate a file
with our genotype data:
```{r}
geno_file <- gt_write_lea_geno(anole_gt)
geno_file
```

Note that the .geno file is placed by default in the same directory and using
the same name as the backing file of the `gen_tibble`

Now can run K clusters from k =1 to k=10:
```{r}
library(LEA)
anole_snmf <- snmf(input.file = geno_file,
                   K = 1:10,
                   entropy = TRUE,
                   repetitions = 5,
                   alpha = 100
                  )
```

Look at https://connor-french.github.io/intro-pop-structure-r/ for how to wrangle the data for plotting. But we should just be able ot grab functions
designed for ADMXITURE and use those on the Q matrices created by sNMF. So, we need some tidiers.
